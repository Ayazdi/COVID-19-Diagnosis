{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COVID = './dataset/train/covid/'\n",
    "PATH_NORMAL = './dataset/train/normal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_list = os.listdir(PATH_COVID)\n",
    "normal_list = os.listdir(PATH_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reshape_img(image):\n",
    "    img = load_img(image, target_size=(224, 224))\n",
    "    x = img_to_array(img)/255.\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preproccesing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [08:24<00:00, 10.74s/it]\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                                    rescale=1./255,\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    brightness_range=[0.2,1.0],\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=[0.5,1.0],\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "for xr in tqdm.tqdm(covid_list):\n",
    "    X = np.array([load_reshape_img(PATH_COVID + image) for image in covid_list])\n",
    "    X = X.reshape(X.shape[0], 224, 224, 3)    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(X, batch_size=70,\n",
    "                              save_to_dir=PATH_COVID, \n",
    "                              save_prefix='covid', \n",
    "                              save_format='jpeg'):        \n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [02:07<00:00,  6.35s/it]\n"
     ]
    }
   ],
   "source": [
    "for xr in tqdm.tqdm(normal_list):\n",
    "    X = np.array([load_reshape_img(PATH_NORMAL + image) for image in normal_list])\n",
    "    X = X.reshape(X.shape[0], 224, 224, 3)    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(X, batch_size=70,\n",
    "                              save_to_dir=PATH_NORMAL, \n",
    "                              save_prefix='normal', \n",
    "                              save_format='jpeg'):        \n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3 = InceptionV3(weights='imagenet', include_top=False, classes=2, input_shape=(224, 224, 3))\n",
    "new_layers = model_v3.output\n",
    "\n",
    "new_layers = GlobalAveragePooling2D()(new_layers)\n",
    "\n",
    "new_layers = Dense(128, activation='relu')(new_layers)\n",
    "new_layers = Dropout(0.5)(new_layers)\n",
    "new_layers = BatchNormalization()(new_layers)\n",
    "\n",
    "new_layers = Dense(2, activation='softmax')(new_layers)\n",
    "model_v3 = Model(inputs=model_v3.inputs, outputs=new_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the first 51 layers\n",
    "for layer in model_v3.layers[:52]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v3.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy']) #Stochastic gradient descent optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22485 images belonging to 2 classes.\n",
      "Found 5621 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 702 steps, validate for 175 steps\n",
      "Epoch 1/2\n",
      "702/702 [==============================] - 3581s 5s/step - loss: 0.3781 - accuracy: 0.8383 - val_loss: 76.9682 - val_accuracy: 0.8450\n",
      "Epoch 2/2\n",
      "702/702 [==============================] - 3468s 5s/step - loss: 0.0976 - accuracy: 0.9829 - val_loss: 76.3031 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29dabd28648>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './dataset/train/',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        './dataset/train/', # same directory as training data\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        subset='validation') # set as validation data\n",
    "\n",
    "model_v3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 32,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // 32,\n",
    "    epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "def save_model(model):\n",
    "    # serialize model to JSON\n",
    "    with open(f\"{model}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_v3.to_json())\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model_v3.save_weights(f\"{model}.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "save_model('model_2')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST = './dataset/valid/'\n",
    "test_list = os.listdir(PATH_TEST)\n",
    "\n",
    "Xtest = np.array([load_reshape_img(PATH_TEST + image) for image in test_list])\n",
    "Xtest = Xtest.reshape(Xtest.shape[0], 224, 224, 3)\n",
    "ytest = []\n",
    "for i in test_list:\n",
    "    if 'normal' in i:\n",
    "        ytest.append(1)\n",
    "    else:\n",
    "        ytest.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       covid       0.96      1.00      0.98        23\n",
      "      normal       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.97        31\n",
      "   macro avg       0.98      0.94      0.96        31\n",
      "weighted avg       0.97      0.97      0.97        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_v3.predict(Xtest, batch_size=64, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(ytest, y_pred_bool, target_names=['covid', 'normal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
